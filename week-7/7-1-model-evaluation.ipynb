{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation in Reggression Models:\n",
    "- To build a model to accuretly predict an unknow case, we have to perform regression evaluation after building the model.\n",
    "    - train and test on the same dataset\n",
    "    - train/test split \n",
    "- Regression Evaluation Metrics\n",
    "- Model oluşturulduktan sonra Evaluation Model oluşturulur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train and test on the same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Data/FuelConsumption.csv\")\n",
    "cdf=df[['ENGINESIZE', 'CYLINDERS', 'FUELCONSUMPTION_COMB', 'CO2EMISSIONS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENGINESIZE</th>\n",
       "      <th>CYLINDERS</th>\n",
       "      <th>FUELCONSUMPTION_COMB</th>\n",
       "      <th>CO2EMISSIONS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>8.5</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.4</td>\n",
       "      <td>4</td>\n",
       "      <td>9.6</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>4</td>\n",
       "      <td>5.9</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.5</td>\n",
       "      <td>6</td>\n",
       "      <td>11.1</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5</td>\n",
       "      <td>6</td>\n",
       "      <td>10.6</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.5</td>\n",
       "      <td>6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.5</td>\n",
       "      <td>6</td>\n",
       "      <td>10.1</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.7</td>\n",
       "      <td>6</td>\n",
       "      <td>11.1</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.7</td>\n",
       "      <td>6</td>\n",
       "      <td>11.6</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.4</td>\n",
       "      <td>4</td>\n",
       "      <td>9.2</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENGINESIZE  CYLINDERS  FUELCONSUMPTION_COMB  CO2EMISSIONS\n",
       "0         2.0          4                   8.5           196\n",
       "1         2.4          4                   9.6           221\n",
       "2         1.5          4                   5.9           136\n",
       "3         3.5          6                  11.1           255\n",
       "4         3.5          6                  10.6           244\n",
       "5         3.5          6                  10.0           230\n",
       "6         3.5          6                  10.1           232\n",
       "7         3.7          6                  11.1           255\n",
       "8         3.7          6                  11.6           267\n",
       "9         2.4          4                   9.2           212"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use entire dataset for training. For example, assume that we have 10 records in our dataset. We select a small partion of the dataset, such as row 6 to 9. (Independent variables)\n",
    "\n",
    "The labels are called \"Actual values\" of the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- hing \"traning accuracy\"\n",
    " - A hing training accuracy isn't necessarily a good thing. \n",
    " - Over-fit (noise'leri alarak genel bir model değil sadece o dataya göre model oluşturmuştur)\n",
    "\n",
    "- low \"out-of-sample accuracy\"\n",
    "  -\"low out-of-sample accuracy\" ifadesi, bir modelin yeni veri örnekleri üzerinde düşük bir başarı elde ettiğini ifade eder. Bu durum, modelin aşırı uymış olabileceğini veya eğitim verilerine çok spesifik olarak uyarlanmış olabileceğini gösterebilir. Modelin eğitim verileri üzerinde iyi performans göstermesine rağmen, genel olarak veri setine uyum sağlamakta zorlanıyor olabilir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mutually exclusive\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics in Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected=[1.0]*11\n",
    "predicted=[round(1.0 - i*0.1, 1) for i in range(11)] #tahminlerin giderek kötüleşmeye başlaması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real values:  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "predicted values: [1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Real values: \", expected)\n",
    "print(\"predicted values:\", predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.5\n"
     ]
    }
   ],
   "source": [
    "mae=mean_absolute_error(expected, predicted)\n",
    "print(\"MAE:\", mae)\n",
    "#eşit artan bir hata yoğunluğu vardır. 0.5 olduğu için"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(expected)):\n\u001b[0;32m      4\u001b[0m     error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mabs\u001b[39m(expected[i]\u001b[38;5;241m-\u001b[39mpredicted[i])\n\u001b[1;32m----> 5\u001b[0m     \u001b[43merrors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m[\u001b[49m\u001b[43merror\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#beklenen, tahmin edilen ve hatanın lineer bir şekilde artması\n",
    "errors=[]\n",
    "for i in range(len(expected)):\n",
    "    error=abs(expected[i]-predicted[i])\n",
    "    errors.append[error]\n",
    "    print(f\" {expected[i]} - {predicted[i]} - {error:.2f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Görselleştirme\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot\n\u001b[1;32m----> 3\u001b[0m pyplot\u001b[38;5;241m.\u001b[39mxticks(ticks\u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m)], labels\u001b[38;5;241m=\u001b[39mpredicted)\n\u001b[0;32m      4\u001b[0m pyplot\u001b[38;5;241m.\u001b[39mplot(errors)\n\u001b[0;32m      5\u001b[0m pyplot\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "#Görselleştirme\n",
    "from matplotlib import pyplot\n",
    "pyplot.xticks(ticks= [i for i in range(len(errors))], labels=predicted)\n",
    "pyplot.plot(errors)\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.35000000000000003\n"
     ]
    }
   ],
   "source": [
    "mse=mean_squared_error(expected, predicted)\n",
    "print(\"MSE: \", mse)\n",
    "#küçük hata payları için daha düşük sonuçlar elde ediliyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors=[]\n",
    "for i in range(len(expected)):\n",
    "    error=abs(expected[i]-predicted[i])\n",
    "    errors.append[error]\n",
    "    print(f\" {expected[i]} - {predicted[i]} - {error:.2f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Görselleştirme\n",
    "from matplotlib import pyplot\n",
    "pyplot.xticks(ticks= [i for i in range(len(errors))], labels=predicted)\n",
    "pyplot.plot(errors)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root Mean Squared Error (RMSE)\n",
    "- MSE'nin karekökü alınarak hesaplanır.\n",
    "- RMSE is interpretable in the same units as the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.5916079783099616\n"
     ]
    }
   ],
   "source": [
    "rmse=np.sqrt(mean_squared_error(expected, predicted))\n",
    "print(\"RMSE: \", rmse)\n",
    "#doğrudan karşılaştırmaya yapabiliriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.5916079783099616\n"
     ]
    }
   ],
   "source": [
    "# farklı hesaplama yöntemi\n",
    "rmse=(mean_squared_error(expected, predicted, squared=False))\n",
    "print(\"RMSE: \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relative Absolute Error (RAE)\n",
    "Relative Squared Error (RSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared (r2) Score\n",
    "- The higher the r2 score, the better the model fits your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Squared Score:  0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2=r2_score(expected, predicted)\n",
    "print(\"R-Squared Score: \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blog Yazısı: \n",
    "https://developer.nvidia.com/blog/a-comprehensive-overview-of-regression-evaluation-metrics/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
